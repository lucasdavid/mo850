{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Lucas David](http://github.com/lucasdavid)  \n",
    "This notebook can be downloaded at https://github.com/lucasdavid/mo850/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.stats.contingency_tables\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras import Input, Model, callbacks\n",
    "from keras.layers import Dense, BatchNormalization, Activation\n",
    "from keras.datasets.cifar10 import load_data\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpaired Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following datasets will be loaded: a.csv b.csv c.csv d.csv e.csv\n",
      "Sample of a loaded dataset:\n",
      "    measure group\n",
      "0  4.249030     a\n",
      "1  5.542826     a\n",
      "2  5.161981     a\n",
      "3  2.267553     a\n",
      "4  4.155343     a\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/3/'\n",
    "\n",
    "datasets = [letter + '.csv' for letter in 'abcde']\n",
    "print('The following datasets will be loaded:', *datasets)\n",
    "\n",
    "datasets = [pd.read_csv(os.path.join(data_dir, d), header=None, names=['measure'])\n",
    "            for d in datasets]\n",
    "\n",
    "for tag, d in zip('abcde', datasets):\n",
    "    d['group'] = tag\n",
    "\n",
    "print('Sample of a loaded dataset:',\n",
    "      datasets[0].head(),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for anova test: 3.3595478270572274e-12\n"
     ]
    }
   ],
   "source": [
    "s, p = stats.f_oneway(*(d['measure'] for d in datasets))\n",
    "print('p-value for anova test:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
      "============================================\n",
      "group1 group2 meandiff  lower  upper  reject\n",
      "--------------------------------------------\n",
      "  a      b    -0.5373   -1.514 0.4395 False \n",
      "  a      c     1.831    0.8718 2.7901  True \n",
      "  a      d     1.908    1.0037 2.8123  True \n",
      "  a      e     1.7006   0.7414 2.6597  True \n",
      "  b      c     2.3682   1.3405 3.396   True \n",
      "  b      d     2.4453   1.4685 3.422   True \n",
      "  b      e     2.2379   1.2101 3.2656  True \n",
      "  c      d     0.077   -0.8821 1.0362 False \n",
      "  c      e    -0.1304  -1.1414 0.8807 False \n",
      "  d      e    -0.2074  -1.1665 0.7518 False \n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "merged_datasets = pd.concat(datasets)\n",
    "r = pairwise_tukeyhsd(merged_datasets['measure'],\n",
    "                      groups=merged_datasets['group'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for Kruskal-Wallis: 2.275373540934311e-09\n"
     ]
    }
   ],
   "source": [
    "s, p = stats.kruskal(*(d['measure'] for d in datasets))\n",
    "print('p-value for Kruskal-Wallis:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   p    p holm  p bonferroni\n",
      "pairs                                       \n",
      "(a, b)  2.433450e-01  0.973380      1.000000\n",
      "(a, c)  1.332963e-04  0.000800      0.001333\n",
      "(a, d)  5.508804e-06  0.000050      0.000055\n",
      "(a, e)  1.515892e-04  0.000800      0.001516\n",
      "(b, c)  6.598469e-06  0.000053      0.000066\n",
      "(b, d)  9.583666e-07  0.000010      0.000010\n",
      "(b, e)  2.789325e-05  0.000195      0.000279\n",
      "(c, d)  5.452595e-01  1.000000      1.000000\n",
      "(c, e)  8.505281e-01  1.000000      1.000000\n",
      "(d, e)  5.883647e-01  1.000000      1.000000\n"
     ]
    }
   ],
   "source": [
    "pairs_indices = list(combinations('abcde', 2))\n",
    "pairs_data = combinations([d['measure'] for d in datasets], 2)\n",
    "\n",
    "ps = [stats.ranksums(x, y)[1] for x, y in pairs_data]\n",
    "ps_holm = multipletests(ps, method='holm')[1]\n",
    "ps_bonferroni = multipletests(ps, method='bonferroni')[1]\n",
    "\n",
    "ps = pd.DataFrame({\n",
    "    'pairs': pairs_indices,\n",
    "    'p': ps,\n",
    "    'p holm': ps_holm,\n",
    "    'p bonferroni': ps_bonferroni\n",
    "}).set_index('pairs')[['p', 'p holm', 'p bonferroni']]\n",
    "\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following datasets will be loaded: multi.csv\n",
      "           0          1          2           3           4\n",
      "0  34.381581  38.230745  52.236630   59.027814   28.288420\n",
      "1  78.475309  74.647168  82.374582   95.970556   28.983943\n",
      "2   5.676301   8.919621  16.492051   28.646045   29.585645\n",
      "3  90.357392  90.869337  98.987833  112.835174  118.070135\n",
      "4  72.198253  71.068576  79.561990   92.640627   72.266390\n",
      "        mean        std\n",
      "0  44.040644  26.147748\n",
      "1  44.989482  26.359810\n",
      "2  55.163707  25.936504\n",
      "3  65.438923  27.269594\n",
      "4  48.367785  29.785974\n"
     ]
    }
   ],
   "source": [
    "dataset = 'multi.csv'\n",
    "print('The following datasets will be loaded:', dataset)\n",
    "\n",
    "dataset = pd.read_csv(os.path.join(data_dir, dataset), header=None)\n",
    "d_stats = pd.DataFrame({\n",
    "    'mean': dataset.mean(axis=0),\n",
    "    'std': dataset.std(axis=0)\n",
    "})\n",
    "\n",
    "print(dataset.head())\n",
    "print(d_stats)\n",
    "\n",
    "maybe_faster = d_stats.loc[0, 'mean'] < d_stats['mean'].loc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 9.195616602651903e-09\n"
     ]
    }
   ],
   "source": [
    "s, p = stats.friedmanchisquare(*(dataset[c] for c in dataset.columns))\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values with wilconxon sign rank test:\n",
      "0.30878760631195334\n",
      "0.0005991194011680517\n",
      "0.0002930525201924893\n",
      "0.12392922503869737\n",
      "\n",
      "Using holm correction:\n",
      "                  p  significantly_faster\n",
      "algorithm                                \n",
      "1          0.308788                 False\n",
      "2          0.001797                  True\n",
      "3          0.001172                  True\n",
      "4          0.247858                 False\n",
      "\n",
      "Using bonferroni correction:\n",
      "                  p  significantly_faster\n",
      "algorithm                                \n",
      "1          1.000000                 False\n",
      "2          0.002396                  True\n",
      "3          0.001172                  True\n",
      "4          0.495717                 False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps = [stats.wilcoxon(dataset[0], dataset[c])[1] for c in range(1, 5)]\n",
    "print('p-values with wilconxon sign rank test:', *ps, sep='\\n', end='\\n\\n')\n",
    "\n",
    "for method in ('holm', 'bonferroni'):\n",
    "    print('Using', method, 'correction:')\n",
    "    rejected_hypotesis, corrected_ps, *_ = multipletests(ps, method=method)\n",
    "\n",
    "    d = pd.DataFrame({\n",
    "        'algorithm': list(range(1, 5)),\n",
    "        'p': corrected_ps,\n",
    "        'significantly_faster': rejected_hypotesis & maybe_faster\n",
    "    }).set_index('algorithm')\n",
    "    print(d, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemenyi procedure:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.028130</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.191307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.028130</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.152054</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.152054</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.020215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.191307</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0 -1.000000  0.900000  0.004719  0.001000  0.052271\n",
       "1  0.900000 -1.000000  0.028130  0.001000  0.191307\n",
       "2  0.004719  0.028130 -1.000000  0.152054  0.900000\n",
       "3  0.001000  0.001000  0.152054 -1.000000  0.020215\n",
       "4  0.052271  0.191307  0.900000  0.020215 -1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Nemenyi procedure:')\n",
    "# scikit-posthocs can be found at:\n",
    "# https://github.com/maximtrp/scikit-posthocs\n",
    "sp.posthoc_nemenyi_friedman(dataset.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Homework for ML Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1024) [[ 0.70603675  0.69816273  0.70341207 ...  0.42519685  0.42782152\n",
      "   0.45144357]\n",
      " [-0.39370079 -0.69816273 -0.59580052 ... -0.7664042  -0.77165354\n",
      "  -0.75328084]\n",
      " [ 0.68766404  0.50131234  0.49606299 ...  0.03149606  0.05249344\n",
      "   0.11023622]]\n",
      "(1000,) [0 8 7]\n",
      " data statistics: -0.033318702837926505 0.4933701274820272\n",
      "label statistics: {0: 97, 1: 105, 2: 101, 3: 103, 4: 97, 5: 98, 6: 101, 7: 108, 8: 87, 9: 103}\n"
     ]
    }
   ],
   "source": [
    "samples_used = 1000\n",
    "\n",
    "(x, y), _ = load_data()\n",
    "x = x.astype(float)\n",
    "x /= 127.\n",
    "x -= 1.\n",
    "\n",
    "# Gray-scale, 1-rank tensors.\n",
    "x = x.mean(axis=-1).reshape(x.shape[0], -1)\n",
    "y = y.ravel()\n",
    "\n",
    "p = np.random.permutation(x.shape[0])[:samples_used]\n",
    "x, y = x[p], y[p]\n",
    "\n",
    "print(x.shape, x[:3])\n",
    "print(y.shape, y[:3])\n",
    "\n",
    "print(' data statistics:', x.mean(), x.std())\n",
    "print('label statistics:', dict(zip(*np.unique(y, return_counts=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(estimator):\n",
    "    if estimator == 'a':\n",
    "        return SVC()\n",
    "    elif estimator == 'b':\n",
    "        x = Input(shape=[1024])\n",
    "        y = Dense(512, use_bias=False)(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Dense(512, use_bias=False)(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Dense(10, activation='softmax')(y)\n",
    "        model = Model(inputs=x, outputs=y)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError('unknown estimator of type `%s`' % estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing experiment 0\n",
      "Executing experiment 1\n",
      "Executing experiment 2\n",
      "Executing experiment 3\n",
      "Executing experiment 4\n"
     ]
    }
   ],
   "source": [
    "r = np.random.RandomState(42)\n",
    "\n",
    "experiments = 5\n",
    "answers, scores = [], []\n",
    "\n",
    "for experiment in range(experiments):\n",
    "    print('Executing experiment', experiment)\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r)\n",
    "    \n",
    "    for train_indices, test_indices in skf.split(x, y):\n",
    "        x_train, y_train = (d[train_indices] for d in (x, y))\n",
    "        x_test, y_test = (d[test_indices] for d in (x, y))\n",
    "        \n",
    "        fit_params = {\n",
    "            'a': dict(),\n",
    "            'b': dict(epochs=100, verbose=0, batch_size=None,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[\n",
    "                          callbacks.TerminateOnNaN(),\n",
    "                          callbacks.EarlyStopping(patience=5)])\n",
    "        }\n",
    "\n",
    "        for estimator in 'ab':\n",
    "            e = build_model(estimator)\n",
    "            e.fit(x_train, y_train, **fit_params[estimator])\n",
    "            \n",
    "            if isinstance(e, Model):\n",
    "                evaluation = e.evaluate(x_test, y_test, verbose=0, batch_size=None)\n",
    "                score = evaluation[1]\n",
    "                scores += [score]\n",
    "            elif isinstance(e, SVC):\n",
    "                scores += [e.score(x_test, y_test)]\n",
    "            \n",
    "            p = e.predict(x_test)\n",
    "            \n",
    "            if isinstance(e, Model):\n",
    "                p = np.argmax(p, axis=-1)\n",
    "            \n",
    "            answers += [p.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model a's average score: 0.2520001280081925\n",
      "model b's average score: 0.2202348950805874\n",
      "On average, model a performed better.\n"
     ]
    }
   ],
   "source": [
    "answers, scores = map(np.asarray, (answers, scores))\n",
    "scores_a = scores[::2]\n",
    "scores_b = scores[1::2]\n",
    "\n",
    "print('model a\\'s average score:', scores_a.mean())\n",
    "print('model b\\'s average score:', scores_b.mean())\n",
    "\n",
    "print('On average, model',\n",
    "      'a' if scores_a.mean() > scores_b.mean() else 'b',\n",
    "      'performed better.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value from wilconxon test: 0.007685794055213263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldavid/envs/tf/lib/python3.6/site-packages/scipy/stats/morestats.py:2385: UserWarning: Warning: sample size too small for normal approximation.\n",
      "  warnings.warn(\"Warning: sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "s, p = stats.wilcoxon(scores_a, scores_b)\n",
    "print('p-value from wilconxon test:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples of model a's predictions: [9 7 9 ... 1 3 7]\n",
      "samples of model b's predictions: [9 5 8 ... 3 3 6]\n",
      "contigency table:\n",
      "col_0    0    1   2    3    4    5    6    7    8    9\n",
      "row_0                                                 \n",
      "0      327   19  73   56   42   10   19   35   56   30\n",
      "1        6  169   7   21   26   16    7   19   47   56\n",
      "2        7   13  95   75   50   13   43   32   26   16\n",
      "3        6   25  27  158   36   36   44   26   23    6\n",
      "4       40   26  52   65  113   73   54   62   32   27\n",
      "5        9   11  14   60   37  124   19   48   22    5\n",
      "6        5   38  74  130   50   46  159   57   36    9\n",
      "7       23   11  46   68   51   78   96  167   11   12\n",
      "8       65   15  14   24   25    9    6    4  209   21\n",
      "9       45  121   8   33   49   11   29   47   64  343\n",
      "p-value from mcnemar test: 0.01463329792022705\n"
     ]
    }
   ],
   "source": [
    "answers_a = np.concatenate(answers[::2])\n",
    "answers_b = np.concatenate(answers[1::2])\n",
    "\n",
    "print('samples of model a\\'s predictions:', answers_a)\n",
    "print('samples of model b\\'s predictions:', answers_b)\n",
    "\n",
    "rc_table = pd.crosstab(answers_a, answers_b)\n",
    "print('contigency table:', rc_table, sep='\\n')\n",
    "\n",
    "p = statsmodels.stats.contingency_tables.mcnemar(rc_table).pvalue\n",
    "print('p-value from mcnemar test:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both wilconxon and McNemar returned *p-values* bellow 5%, indicating model **a** is indeed better than model **b**. Wilconxon, however, is more powerful (0.00769 < 0.01463)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
